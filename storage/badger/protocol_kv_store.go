package badger

import (
	"fmt"
	"github.com/dgraph-io/badger/v2"
	"github.com/onflow/flow-go/model/flow"
	"github.com/onflow/flow-go/module"
	"github.com/onflow/flow-go/module/metrics"
	"github.com/onflow/flow-go/storage"
	"github.com/onflow/flow-go/storage/badger/operation"
	"github.com/onflow/flow-go/storage/badger/transaction"
)

// DefaultProtocolKVStoreCacheSize is the default size for primary protocol KV store cache.
// KV store is rarely updated, so we will have a limited number of unique states.
// Lets be generous and assume we have 10 different KV stores used at the same time.
var DefaultProtocolKVStoreCacheSize uint = 10

// DefaultProtocolKVStoreByBlockIDCacheSize is the default value for secondary byBlockIdCache.
// We want to be able to cover a broad interval of views without cache misses, so we use a bigger value.
var DefaultProtocolKVStoreByBlockIDCacheSize uint = 1000

type ProtocolKVStore struct {
	db *badger.DB

	// cache is essentially an in-memory map from `ProtocolStateEntry.ID()` -> `RichProtocolStateEntry`
	// We do _not_ populate this cache which holds the RichProtocolStateEntrys on store. This is because
	//   (i) we don't have the RichProtocolStateEntry on store readily available and
	//  (ii) new RichProtocolStateEntry are really rare throughout an epoch, so the total cost of populating
	//       the cache becomes negligible over several views.
	// In the future, we might want to populate the cache on store, if we want to maintain frequently-changing
	// information in the protocol state, like the latest sealed block. This should be a smaller amount of work,
	// because the `ProtocolStateEntry` is generated by `StateMutator.Build()`. The `StateMutator` should already
	// have the needed Epoch Setup and Commit events, since it starts with a RichProtocolStateEntry for the parent
	// state and consumes Epoch Setup and Epoch Commit events. Though, we leave this optimization for later.
	//
	// `cache` only holds the distinct Protocol States. On the happy path, we expect something like 3 entries per epoch.
	// On the optimal happy path we have 3 entries per epoch: one entry on epoch Switchover, one on receiving the Epoch Setup
	// and one when seeing the Epoch Commit event. Let's be generous and assume we have 20 different Protocol States per epoch.
	// Beyond that, we are certainly leaving the domain of normal operations that we optimize for. Therefore, a cache size of
	// roughly 100 is a reasonable balance between performance and memory consumption.
	cache *Cache[flow.Identifier, *storage.KeyValueStoreData]

	// byBlockIdCache is essentially an in-memory map from `Block.ID()` -> `ProtocolStateEntry.ID()`. The full
	// Protocol state can be retrieved from the `cache` above.
	// We populate the `byBlockIdCache` on store, because a new entry is added for every block and we probably also
	// query the Protocol state for every block. So argument (ii) from above does not apply here. Furthermore,
	// argument (i) from above also does not apply, because we already have the Protocol State's ID on store,
	// so populating the cache is easy.
	//
	// `byBlockIdCache` will contain an entry for every block. We want to be able to cover a broad interval of views
	// without cache misses, so a cache size of roughly 1000 entries is reasonable.
	byBlockIdCache *Cache[flow.Identifier, flow.Identifier]
}

var _ storage.ProtocolKVStore = (*ProtocolKVStore)(nil)

func NewProtocolKVStore(collector module.CacheMetrics,
	db *badger.DB,
	stateCacheSize uint,
	stateByBlockIDCacheSize uint,
) *ProtocolKVStore {
	retrieveByStateID := func(stateID flow.Identifier) func(tx *badger.Txn) (*storage.KeyValueStoreData, error) {
		return func(tx *badger.Txn) (*storage.KeyValueStoreData, error) {
			var kvStore storage.KeyValueStoreData
			err := operation.RetrieveProtocolKVStore(stateID, &kvStore)(tx)
			if err != nil {
				return nil, err
			}
			return &kvStore, nil
		}
	}

	storeByBlockID := func(blockID flow.Identifier, stateID flow.Identifier) func(*transaction.Tx) error {
		return func(tx *transaction.Tx) error {
			err := transaction.WithTx(operation.IndexProtocolKVStore(blockID, stateID))(tx)
			if err != nil {
				return fmt.Errorf("could not index protocol state for block (%x): %w", blockID[:], err)
			}
			return nil
		}
	}

	retrieveByBlockID := func(blockID flow.Identifier) func(tx *badger.Txn) (flow.Identifier, error) {
		return func(tx *badger.Txn) (flow.Identifier, error) {
			var stateID flow.Identifier
			err := operation.LookupProtocolState(blockID, &stateID)(tx)
			if err != nil {
				return flow.ZeroID, fmt.Errorf("could not lookup protocol state ID for block (%x): %w", blockID[:], err)
			}
			return stateID, nil
		}
	}

	return &ProtocolKVStore{
		db: db,
		cache: newCache[flow.Identifier, *storage.KeyValueStoreData](collector, metrics.ResourceProtocolKVStore,
			withLimit[flow.Identifier, *storage.KeyValueStoreData](stateCacheSize),
			withStore(noopStore[flow.Identifier, *storage.KeyValueStoreData]),
			withRetrieve(retrieveByStateID)),
		byBlockIdCache: newCache[flow.Identifier, flow.Identifier](collector, metrics.ResourceProtocolKVStoreByBlockID,
			withLimit[flow.Identifier, flow.Identifier](stateByBlockIDCacheSize),
			withStore(storeByBlockID),
			withRetrieve(retrieveByBlockID)),
	}
}

func (s *ProtocolKVStore) StoreTx(stateID flow.Identifier, data *storage.KeyValueStoreData) func(*transaction.Tx) error {
	return transaction.WithTx(operation.InsertProtocolKVStore(stateID, data))
}

func (s *ProtocolKVStore) IndexTx(blockID flow.Identifier, stateID flow.Identifier) func(*transaction.Tx) error {
	return s.byBlockIdCache.PutTx(blockID, stateID)
}

func (s *ProtocolKVStore) ByID(id flow.Identifier) (*storage.KeyValueStoreData, error) {
	tx := s.db.NewTransaction(false)
	defer tx.Discard()
	return s.cache.Get(id)(tx)
}

func (s *ProtocolKVStore) ByBlockID(blockID flow.Identifier) (*storage.KeyValueStoreData, error) {
	tx := s.db.NewTransaction(false)
	defer tx.Discard()
	stateID, err := s.byBlockIdCache.Get(blockID)(tx)
	if err != nil {
		return nil, fmt.Errorf("could not lookup protocol state ID for block (%x): %w", blockID[:], err)
	}
	return s.cache.Get(stateID)(tx)
}
